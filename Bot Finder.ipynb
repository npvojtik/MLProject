{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import isinf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "# get the cleaned-up account data into a dataframe\n",
    "# these are the test accounts, not the larger data set\n",
    "filename = 'cleaned_accounts.csv'\n",
    "headers = [\"id\", \"id_str\", \"screen_name\", \"location\", \"description\", \"url\", \"followers_count\", \"friends_count\", \"listed_count\", \"created_at\", \"favourites_count\", \"verified\", \"statuses_count\", \"lang\", \"status\", \"default_profile\", \"default_profile_image\", \"has_extended_profile\", \"name\", \"bot\"]\n",
    "accounts = pd.read_csv(filename, names=headers)\n",
    "\n",
    "# add freinds-to-followers column\n",
    "accounts['ratio'] = accounts['friends_count'] / accounts['followers_count']\n",
    "\n",
    "# remove NaN from description column\n",
    "def remove_NaN(text):\n",
    "    if (pd.isnull(text)):\n",
    "        text = \"\"\n",
    "    else:\n",
    "        text = text\n",
    "    return text\n",
    "\n",
    "accounts['description'] = accounts['description'].apply(remove_NaN)\n",
    "\n",
    "# add column for lexical diversity of the description\n",
    "# lexical diversity function (as written in Shellman [2])\n",
    "# http://www.erinshellman.com/bot-or-not/\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    if (pd.isnull(text)):\n",
    "        diversity = 0\n",
    "    elif len(text) == 0:\n",
    "        diversity = 0\n",
    "    else:\n",
    "        diversity = float(len(set(text))) / len(text)\n",
    "    return diversity\n",
    "\n",
    "accounts['desc_lex_diversity'] = accounts['description'].apply(lexical_diversity)\n",
    "\n",
    "# separate the bots and humans for exploratory diagnostics\n",
    "bots = accounts.loc[accounts['bot'] == 1]\n",
    "humans = accounts.loc[accounts['bot'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the avg, std dev, and median for followers, friends, and friend-to-follower ratio of bot accounts and human accounts\n",
    "b_follower_avg = bots['followers_count'].mean()\n",
    "b_follower_std = bots['followers_count'].std()\n",
    "b_follower_med = bots['followers_count'].median()\n",
    "b_friend_avg = bots['friends_count'].mean()\n",
    "b_friend_std = bots['friends_count'].std()\n",
    "b_friend_med = bots['friends_count'].median()\n",
    "b_ratio_avg = bots['ratio'].mean()\n",
    "b_ratio_std = bots['ratio'].std()\n",
    "b_ratio_med = bots['ratio'].median()\n",
    "\n",
    "h_follower_avg = humans['followers_count'].mean()\n",
    "h_follower_std = humans['followers_count'].std()\n",
    "h_follower_med = humans['followers_count'].median()\n",
    "h_friend_avg = humans['friends_count'].mean()\n",
    "h_friend_std = humans['friends_count'].std()\n",
    "h_friend_med = humans['friends_count'].median()\n",
    "h_ratio_avg = humans['ratio'].mean()\n",
    "h_ratio_std = humans['ratio'].std()\n",
    "h_ratio_med = humans['ratio'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bots:\n",
      "====================================================================================================\n",
      "Followers:\n",
      "Avg: 11887.1000\t\tStd: 25015.9995\t\tMed: 2579.5000\n",
      "\n",
      "Friends:\n",
      "Avg: 275.9800\t\tStd: 883.7261\t\tMed: 2.0000\n",
      "\n",
      "Ratio:\n",
      "Avg: 0.1482\t\tStd: 0.3573\t\tMed: 0.0015\n",
      "\n",
      "Humans:\n",
      "====================================================================================================\n",
      "Followers:\n",
      "Avg: 364099.1400\t\tStd: 920812.4892\t\tMed: 93702.0000\n",
      "\n",
      "Friends:\n",
      "Avg: 873.6000\t\tStd: 1263.8037\t\tMed: 397.0000\n",
      "\n",
      "Ratio:\n",
      "Avg: 0.0248\t\tStd: 0.0968\t\tMed: 0.0066\n"
     ]
    }
   ],
   "source": [
    "# print the diagnostic results\n",
    "print(\"Bots:\")\n",
    "print(\"=\"*100)\n",
    "print(\"Followers:\")\n",
    "print(\"Avg: {:.4f}\\t\\tStd: {:.4f}\\t\\tMed: {:.4f}\".format(b_follower_avg, b_follower_std, b_follower_med))\n",
    "print(\"\\nFriends:\")\n",
    "print(\"Avg: {:.4f}\\t\\tStd: {:.4f}\\t\\tMed: {:.4f}\".format(b_friend_avg, b_friend_std, b_friend_med))\n",
    "print(\"\\nRatio:\")\n",
    "print(\"Avg: {:.4f}\\t\\tStd: {:.4f}\\t\\tMed: {:.4f}\".format(b_ratio_avg, b_ratio_std, b_ratio_med))\n",
    "print(\"\\nHumans:\")\n",
    "print(\"=\"*100)\n",
    "print(\"Followers:\")\n",
    "print(\"Avg: {:.4f}\\t\\tStd: {:.4f}\\t\\tMed: {:.4f}\".format(h_follower_avg, h_follower_std, h_follower_med))\n",
    "print(\"\\nFriends:\")\n",
    "print(\"Avg: {:.4f}\\t\\tStd: {:.4f}\\t\\tMed: {:.4f}\".format(h_friend_avg, h_friend_std, h_friend_med))\n",
    "print(\"\\nRatio:\")\n",
    "print(\"Avg: {:.4f}\\t\\tStd: {:.4f}\\t\\tMed: {:.4f}\".format(h_ratio_avg, h_ratio_std, h_ratio_med))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification ratio for bots: 0.0200\n",
      "Verification ratio for humans: 0.2600\n"
     ]
    }
   ],
   "source": [
    "# get the ratio of verified accounts\n",
    "b_verified = bots['verified'].sum() / len(bots.index)\n",
    "h_verified = humans['verified'].sum() / len(bots.index)\n",
    "\n",
    "print(\"Verification ratio for bots: {:.4f}\".format(b_verified))\n",
    "print(\"Verification ratio for humans: {:.4f}\".format(h_verified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bots: Avg: 0.3353\t\tStd: 0.1872\t\tMed: 0.3152\n",
      "Humans: Avg: 0.4309\t\tStd: 0.2317\t\tMed: 0.3741\n"
     ]
    }
   ],
   "source": [
    "# get the lexical diversity avg, std dev, and median\n",
    "b_lexdev_avg = bots['desc_lex_diversity'].mean()\n",
    "b_lexdev_std = bots['desc_lex_diversity'].std()\n",
    "b_lexdev_med = bots['desc_lex_diversity'].median()\n",
    "\n",
    "h_lexdev_avg = humans['desc_lex_diversity'].mean()\n",
    "h_lexdev_std = humans['desc_lex_diversity'].std()\n",
    "h_lexdev_med = humans['desc_lex_diversity'].median()\n",
    "\n",
    "print(\"Bots: Avg: {:.4f}\\t\\tStd: {:.4f}\\t\\tMed: {:.4f}\".format(b_lexdev_avg, b_lexdev_std, b_lexdev_med))\n",
    "print(\"Humans: Avg: {:.4f}\\t\\tStd: {:.4f}\\t\\tMed: {:.4f}\".format(h_lexdev_avg, h_lexdev_std, h_lexdev_med))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier:\n",
      "\tAccuracy: 0.5000\n",
      "\tRecall: 0.0000\n",
      "\tAUC Score: 0.5000\n",
      "\n",
      "Bernoulli Naive Bayes Classifier:\n",
      "\tAccuracy: 0.5000\n",
      "\tRecall: 0.2000\n",
      "\tAUC Score: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# train the bernoulli and multinomial naive bayes models on the screen names\n",
    "scrnames = accounts['screen_name'].tolist()\n",
    "targets = accounts['bot'].tolist()\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(scrnames)\n",
    "\n",
    "clf_mn = MultinomialNB().fit(X_train_counts, targets)\n",
    "clf_bn = BernoulliNB().fit(X_train_counts, targets)\n",
    "\n",
    "cv = 5\n",
    "mn_accuracy = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "mn_recall = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "mn_auc = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print(\"Multinomial Naive Bayes Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(mn_accuracy))\n",
    "print(\"\\tRecall: {:.4f}\".format(mn_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(mn_auc))\n",
    "print()\n",
    "\n",
    "bn_accuracy = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "bn_recall = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "bn_auc = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(bn_accuracy))\n",
    "print(\"\\tRecall: {:.4f}\".format(bn_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(bn_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier:\n",
      "\tAccuracy: 0.5000\n",
      "\tPrecision: 0.5000\n",
      "\tRecall: 1.0000\n",
      "\tAUC Score: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# now train the logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_counts, targets)\n",
    "\n",
    "lr_accuracy = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "lr_precision = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "lr_recall = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "lr_auc = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print(\"Logistic Regression Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(lr_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(lr_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(lr_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier:\n",
      "\tAccuracy: 0.5400\n",
      "\tPrecision: 0.6158\n",
      "\tRecall: 0.6400\n",
      "\tAUC Score: 0.6870\n",
      "\n",
      "Bernoulli Naive Bayes Classifier:\n",
      "\tAccuracy: 0.5400\n",
      "\tPrecision: 0.6158\n",
      "\tRecall: 0.6400\n",
      "\tAUC Score: 0.6130\n",
      "\n",
      "Logistic Regression Classifier:\n",
      "\tAccuracy: 0.5300\n",
      "\tPrecision: 0.5105\n",
      "\tRecall: 0.4400\n",
      "\tAUC Score: 0.5410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/npvojtik/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# train the models on the names\n",
    "scrnames = accounts['name'].tolist()\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(scrnames)\n",
    "\n",
    "clf_mn = MultinomialNB().fit(X_train_counts, targets)\n",
    "clf_bn = BernoulliNB().fit(X_train_counts, targets)\n",
    "\n",
    "cv = 5\n",
    "mn_accuracy = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "mn_precision = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "mn_recall = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "mn_auc = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print(\"Multinomial Naive Bayes Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(mn_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(mn_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(mn_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(mn_auc))\n",
    "print()\n",
    "\n",
    "bn_accuracy = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "bn_precision = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "bn_recall = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "bn_auc = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(bn_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(bn_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(bn_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(bn_auc))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_counts, targets)\n",
    "\n",
    "lr_accuracy = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "lr_precision = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "lr_recall = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "lr_auc = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print()\n",
    "print(\"Logistic Regression Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(lr_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(lr_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(lr_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier:\n",
      "\tAccuracy: 0.5800\n",
      "\tPrecision: 0.5711\n",
      "\tRecall: 0.7200\n",
      "\tAUC Score: 0.6370\n",
      "\n",
      "Bernoulli Naive Bayes Classifier:\n",
      "\tAccuracy: 0.5800\n",
      "\tPrecision: 0.5711\n",
      "\tRecall: 0.7200\n",
      "\tAUC Score: 0.5970\n",
      "\n",
      "Logistic Regression Classifier:\n",
      "\tAccuracy: 0.5800\n",
      "\tPrecision: 0.5711\n",
      "\tRecall: 0.7200\n",
      "\tAUC Score: 0.6370\n"
     ]
    }
   ],
   "source": [
    "# train the models on the URLS\n",
    "scrnames = accounts['url'].tolist()\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(scrnames)\n",
    "\n",
    "clf_mn = MultinomialNB().fit(X_train_counts, targets)\n",
    "clf_bn = BernoulliNB().fit(X_train_counts, targets)\n",
    "\n",
    "cv = 5\n",
    "mn_accuracy = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "mn_precision = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "mn_recall = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "mn_auc = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print(\"Multinomial Naive Bayes Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(mn_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(mn_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(mn_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(mn_auc))\n",
    "print()\n",
    "\n",
    "bn_accuracy = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "bn_precision = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "bn_recall = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "bn_auc = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(bn_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(bn_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(bn_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(bn_auc))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_counts, targets)\n",
    "\n",
    "lr_accuracy = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "lr_precision = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "lr_recall = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "lr_auc = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print()\n",
    "print(\"Logistic Regression Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(lr_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(lr_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(lr_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier:\n",
      "\tAccuracy: 0.7100\n",
      "\tPrecision: 0.7507\n",
      "\tRecall: 0.6400\n",
      "\tAUC Score: 0.7580\n",
      "\n",
      "Bernoulli Naive Bayes Classifier:\n",
      "\tAccuracy: 0.6800\n",
      "\tPrecision: 0.9333\n",
      "\tRecall: 0.3800\n",
      "\tAUC Score: 0.8340\n",
      "\n",
      "Logistic Regression Classifier:\n",
      "\tAccuracy: 0.6900\n",
      "\tPrecision: 0.7543\n",
      "\tRecall: 0.5600\n",
      "\tAUC Score: 0.7570\n"
     ]
    }
   ],
   "source": [
    "# train the models on the descriptions\n",
    "scrnames = accounts['description'].tolist()\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(scrnames)\n",
    "\n",
    "clf_mn = MultinomialNB().fit(X_train_counts, targets)\n",
    "clf_bn = BernoulliNB().fit(X_train_counts, targets)\n",
    "\n",
    "cv = 5\n",
    "mn_accuracy = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "mn_precision = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "mn_recall = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "mn_auc = sum(cross_val_score(clf_mn, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print(\"Multinomial Naive Bayes Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(mn_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(mn_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(mn_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(mn_auc))\n",
    "print()\n",
    "\n",
    "bn_accuracy = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "bn_precision = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "bn_recall = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "bn_auc = sum(cross_val_score(clf_bn, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(bn_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(bn_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(bn_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(bn_auc))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_counts, targets)\n",
    "\n",
    "lr_accuracy = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='accuracy'))/cv\n",
    "lr_precision = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='precision'))/cv\n",
    "lr_recall = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='recall'))/cv\n",
    "lr_auc = sum(cross_val_score(lr, X_train_counts, targets, cv=cv, scoring='roc_auc'))/cv\n",
    "\n",
    "print()\n",
    "print(\"Logistic Regression Classifier:\")\n",
    "print(\"\\tAccuracy: {:.4f}\".format(lr_accuracy))\n",
    "print(\"\\tPrecision: {:.4f}\".format(lr_precision))\n",
    "print(\"\\tRecall: {:.4f}\".format(lr_recall))\n",
    "print(\"\\tAUC Score: {:.4f}\".format(lr_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
